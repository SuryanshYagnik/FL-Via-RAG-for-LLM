{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8831896,"sourceType":"datasetVersion","datasetId":5314260},{"sourceId":11371,"sourceType":"modelInstanceVersion","modelInstanceId":5171,"modelId":3533}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Model used\n\nWe are using **Gemma** model with 2B parameters, Keras, English version, v2.\n\n## Dataset\n\nWe will fine-tune **Gemma** using a [Medical Q & A](https://www.kaggle.com/datasets/gpreda/medquad/) dataset. This is a subset of the full public dataset [Healthcare NLP: LLMs, Transformers, Datasets](https://www.kaggle.com/datasets/jpmiller/layoutlm).\n\n","metadata":{}},{"cell_type":"markdown","source":"# Prepare packages\n\n\nWe will install updated version of Keras, KerasNLP, which we need for fine-tuning, and other dependencies.","metadata":{}},{"cell_type":"code","source":"# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n!pip install -q -U tf-keras\n!pip install -q -U keras-nlp==0.10.0\n!pip install -q -U keras>=3","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:21:07.470428Z","iopub.execute_input":"2024-11-10T10:21:07.471031Z","iopub.status.idle":"2024-11-10T10:23:19.111293Z","shell.execute_reply.started":"2024-11-10T10:21:07.471001Z","shell.execute_reply":"2024-11-10T10:23:19.110145Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.18.0 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.1 requires keras<2.16,>=2.15.0, but you have keras 3.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\" # avoid memory fragmentation on JAX backend.\nos.environ[\"JAX_PLATFORMS\"] = \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T10:23:23.602662Z","iopub.execute_input":"2024-11-10T10:23:23.603020Z","iopub.status.idle":"2024-11-10T10:23:23.608058Z","shell.execute_reply.started":"2024-11-10T10:23:23.602988Z","shell.execute_reply":"2024-11-10T10:23:23.607129Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import keras_nlp\nimport keras\nimport csv\n\nprint(\"KerasNLP version: \", keras_nlp.__version__)\nprint(\"Keras version: \", keras.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T10:23:25.421955Z","iopub.execute_input":"2024-11-10T10:23:25.422330Z","iopub.status.idle":"2024-11-10T10:23:31.961639Z","shell.execute_reply.started":"2024-11-10T10:23:25.422278Z","shell.execute_reply":"2024-11-10T10:23:31.960662Z"}},"outputs":[{"name":"stderr","text":"2024-11-10 10:23:25.865041: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-11-10 10:23:25.865103: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-11-10 10:23:25.866574: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"KerasNLP version:  0.10.0\nKeras version:  3.6.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Load the model","metadata":{}},{"cell_type":"code","source":"gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:23:35.723145Z","iopub.execute_input":"2024-11-10T10:23:35.723788Z","iopub.status.idle":"2024-11-10T10:24:16.685879Z","shell.execute_reply.started":"2024-11-10T10:23:35.723756Z","shell.execute_reply":"2024-11-10T10:24:16.685096Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'preprocessor.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"gemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:24:25.398488Z","iopub.execute_input":"2024-11-10T10:24:25.398830Z","iopub.status.idle":"2024-11-10T10:24:25.428200Z","shell.execute_reply.started":"2024-11-10T10:24:25.398806Z","shell.execute_reply":"2024-11-10T10:24:25.427327Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Prepare the training data","metadata":{}},{"cell_type":"markdown","source":"We prepare the **Medical Q & A** data for training. We will load the data using the template where, for each data that will be included in the training set, we provide pairs of questions and answers.","metadata":{}},{"cell_type":"code","source":"data = []\n\n# The CSV file contains two columns 'question' and 'answer'\nwith open(\"//kaggle/input/medquad/medquad.csv\", mode='r', encoding='utf-8') as file:\n    reader = csv.DictReader(file)\n    for row in reader:\n        # Use a template to format the questions and answers in the CSV into\n        # questions and answers in the data.\n        template = \"Question:\\n{question}\\n\\nAnswer:\\n{answer}\"\n        data.append(template.format(**row))","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:24:30.752366Z","iopub.execute_input":"2024-11-10T10:24:30.753149Z","iopub.status.idle":"2024-11-10T10:24:31.085222Z","shell.execute_reply.started":"2024-11-10T10:24:30.753120Z","shell.execute_reply":"2024-11-10T10:24:31.084308Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"len(data)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:24:34.726328Z","iopub.execute_input":"2024-11-10T10:24:34.727155Z","iopub.status.idle":"2024-11-10T10:24:34.732687Z","shell.execute_reply.started":"2024-11-10T10:24:34.727123Z","shell.execute_reply":"2024-11-10T10:24:34.731837Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"16412"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"data = data[:300]","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:24:38.285668Z","iopub.execute_input":"2024-11-10T10:24:38.286003Z","iopub.status.idle":"2024-11-10T10:24:38.292562Z","shell.execute_reply.started":"2024-11-10T10:24:38.285980Z","shell.execute_reply":"2024-11-10T10:24:38.291611Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Check model inference before fine tuning","metadata":{}},{"cell_type":"markdown","source":"We wil first check the model before proceeding to fine-tuning. We will test it with some questions about medical matters.  \n\nFirst, we will define an utility function to display the query and answer from LLM.","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, Markdown\ndef colorize_text(text):\n    for word, color in zip([\"Category\", \"Question\", \"Answer\"], [\"blue\", \"red\", \"green\"]):\n        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:25:21.524252Z","iopub.execute_input":"2024-11-10T10:25:21.524639Z","iopub.status.idle":"2024-11-10T10:25:21.530301Z","shell.execute_reply.started":"2024-11-10T10:25:21.524610Z","shell.execute_reply":"2024-11-10T10:25:21.529232Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Let's check how we can display the content of one data input using the `colorize_text` function.","metadata":{}},{"cell_type":"code","source":"print(data[3])","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:25:24.880947Z","iopub.execute_input":"2024-11-10T10:25:24.881674Z","iopub.status.idle":"2024-11-10T10:25:24.887948Z","shell.execute_reply.started":"2024-11-10T10:25:24.881641Z","shell.execute_reply":"2024-11-10T10:25:24.887014Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Question:\nWhat are the treatments for Glaucoma ?\n\nAnswer:\nAlthough open-angle glaucoma cannot be cured, it can usually be controlled. While treatments may save remaining vision, they do not improve sight already lost from glaucoma. The most common treatments for glaucoma are medication and surgery. Medications  Medications for glaucoma may be either in the form of eye drops or pills. Some drugs reduce pressure by slowing the flow of fluid into the eye. Others help to improve fluid drainage. (Watch the video to learn more about coping with glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.) For most people with glaucoma, regular use of medications will control the increased fluid pressure. But, these drugs may stop working over time. Or, they may cause side effects. If a problem occurs, the eye care professional may select other drugs, change the dose, or suggest other ways to deal with the problem.  Read or listen to ways some patients are coping with glaucoma. Surgery Laser surgery is another treatment for glaucoma. During laser surgery, a strong beam of light is focused on the part of the anterior chamber where the fluid leaves the eye. This results in a series of small changes that makes it easier for fluid to exit the eye. Over time, the effect of laser surgery may wear off. Patients who have this form of surgery may need to keep taking glaucoma drugs. Researching Causes and Treatments Through studies in the laboratory and with patients, NEI is seeking better ways to detect, treat, and prevent vision loss in people with glaucoma. For example, researchers have discovered genes that could help explain how glaucoma damages the eye. NEI also is supporting studies to learn more about who is likely to get glaucoma, when to treat people who have increased eye pressure, and which treatment to use first.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"display(Markdown(colorize_text(data[3])))","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:25:28.313502Z","iopub.execute_input":"2024-11-10T10:25:28.314307Z","iopub.status.idle":"2024-11-10T10:25:28.320107Z","shell.execute_reply.started":"2024-11-10T10:25:28.314263Z","shell.execute_reply":"2024-11-10T10:25:28.319135Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWhat are the treatments for Glaucoma ?\n\n\n\n**<font color='green'>Answer:</font>**\nAlthough open-angle glaucoma cannot be cured, it can usually be controlled. While treatments may save remaining vision, they do not improve sight already lost from glaucoma. The most common treatments for glaucoma are medication and surgery. Medications  Medications for glaucoma may be either in the form of eye drops or pills. Some drugs reduce pressure by slowing the flow of fluid into the eye. Others help to improve fluid drainage. (Watch the video to learn more about coping with glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.) For most people with glaucoma, regular use of medications will control the increased fluid pressure. But, these drugs may stop working over time. Or, they may cause side effects. If a problem occurs, the eye care professional may select other drugs, change the dose, or suggest other ways to deal with the problem.  Read or listen to ways some patients are coping with glaucoma. Surgery Laser surgery is another treatment for glaucoma. During laser surgery, a strong beam of light is focused on the part of the anterior chamber where the fluid leaves the eye. This results in a series of small changes that makes it easier for fluid to exit the eye. Over time, the effect of laser surgery may wear off. Patients who have this form of surgery may need to keep taking glaucoma drugs. Researching Causes and Treatments Through studies in the laboratory and with patients, NEI is seeking better ways to detect, treat, and prevent vision loss in people with glaucoma. For example, researchers have discovered genes that could help explain how glaucoma damages the eye. NEI also is supporting studies to learn more about who is likely to get glaucoma, when to treat people who have increased eye pressure, and which treatment to use first."},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"Now we will ask the model to answer to a question for which we know the expected answer.","metadata":{}},{"cell_type":"code","source":"prompt = template.format(\n    question=\"What are the complications of Paget's Disease of Bone ?\",\n    answer=\"\",\n)\nresponse = gemma_lm.generate(prompt, max_length=128)\ndisplay(Markdown(colorize_text(response)))","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:25:31.539969Z","iopub.execute_input":"2024-11-10T10:25:31.540737Z","iopub.status.idle":"2024-11-10T10:25:42.142142Z","shell.execute_reply.started":"2024-11-10T10:25:31.540698Z","shell.execute_reply":"2024-11-10T10:25:42.141186Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWhat are the complications of Paget's Disease of Bone ?\n\n\n\n**<font color='green'>Answer:</font>**\nPaget's disease of bone is a disorder of bone metabolism characterized by excessive bone resorption and osteoclast activity. The disease is characterized by the formation of new bone in the form of osteoid, which is subsequently replaced by mature bone. The disease is characterized by the formation of new bone in the form of osteoid, which is subsequently replaced by mature bone. The disease is characterized by the formation of new bone in the form of osteoid, which is subsequently replaced by mature bone. The disease is characterized by the formation"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"prompt = template.format(\n    question=\"What are the treatments for Diabetes ?\",\n    answer=\"\",\n)\nresponse = gemma_lm.generate(prompt, max_length=128)\ndisplay(Markdown(colorize_text(response)))","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:25:50.749805Z","iopub.execute_input":"2024-11-10T10:25:50.750467Z","iopub.status.idle":"2024-11-10T10:25:53.496963Z","shell.execute_reply.started":"2024-11-10T10:25:50.750436Z","shell.execute_reply":"2024-11-10T10:25:53.495985Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWhat are the treatments for Diabetes ?\n\n\n\n**<font color='green'>Answer:</font>**\nDiabetes is a chronic disease that affects the way your body uses blood sugar (glucose). It is caused by a lack of insulin, a hormone that helps glucose enter your cells to be used for energy.\n\nThere are two types of diabetes:\n\nType 1 diabetes: This is an autoimmune disease in which the body’s immune system attacks the cells that produce insulin. It is often called “insulin-dependent diabetes” or “juvenile diabetes.”\n\nType 2 diabetes: This is the most common type of diabetes. It is caused by a combination of factors"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"# Fine-tunning with LoRA   \n\n\nWe are using now **LoRA** for fine-tunning. **LoRA** stands for **Low Rank Adaptation** and is a method for modifying a pretrained model (for example, an LLM or vision transformer) to better suit a specific, often smaller, dataset by **adjusting only a small, low-rank subset of the model's parameters**.\n","metadata":{}},{"cell_type":"markdown","source":"The rank used here for LoRA controls the number of parameters that will be recalculated during fine-tuning.","metadata":{}},{"cell_type":"code","source":"# Enable LoRA for the model and set the LoRA rank to 3.\ngemma_lm.backbone.enable_lora(rank=3)\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:25:57.190788Z","iopub.execute_input":"2024-11-10T10:25:57.191116Z","iopub.status.idle":"2024-11-10T10:25:57.553526Z","shell.execute_reply.started":"2024-11-10T10:25:57.191092Z","shell.execute_reply":"2024-11-10T10:25:57.552609Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,507,195,392\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,195,392</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,195,392\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,195,392</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,022,976\u001b[0m (3.90 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,022,976</span> (3.90 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Fine-tune on the Medical QA dataset.\n\n# Limit the input sequence length to 128 (to control memory usage).\ngemma_lm.preprocessor.sequence_length = 128\n# Use AdamW (a common optimizer for transformer models).\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n)\n# Exclude layernorm and bias terms from decay.\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\ngemma_lm.fit(data, epochs=10, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:26:05.805662Z","iopub.execute_input":"2024-11-10T10:26:05.806028Z","iopub.status.idle":"2024-11-10T10:36:44.972975Z","shell.execute_reply.started":"2024-11-10T10:26:05.806000Z","shell.execute_reply":"2024-11-10T10:36:44.972125Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 230ms/step - loss: 1.7986 - sparse_categorical_accuracy: 0.5780\nEpoch 2/10\n\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 202ms/step - loss: 1.5287 - sparse_categorical_accuracy: 0.6026\nEpoch 3/10\n\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 202ms/step - loss: 1.4643 - sparse_categorical_accuracy: 0.6122\nEpoch 4/10\n\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 202ms/step - loss: 1.4298 - sparse_categorical_accuracy: 0.6171\nEpoch 5/10\n\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 202ms/step - loss: 1.3984 - sparse_categorical_accuracy: 0.6241\nEpoch 6/10\n\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 202ms/step - loss: 1.3677 - sparse_categorical_accuracy: 0.6294\nEpoch 7/10\n\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 202ms/step - loss: 1.3368 - sparse_categorical_accuracy: 0.6350\nEpoch 8/10\n\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 202ms/step - loss: 1.3033 - sparse_categorical_accuracy: 0.6403\nEpoch 9/10\n\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 202ms/step - loss: 1.2692 - sparse_categorical_accuracy: 0.6476\nEpoch 10/10\n\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 202ms/step - loss: 1.2371 - sparse_categorical_accuracy: 0.6554\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7e53b00f6b90>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# Inference after fine tuning\nWe will run now the queries through the fine-tuned model.","metadata":{}},{"cell_type":"code","source":"prompt = template.format(\n    question=\"What are the complications of Paget's Disease of Bone ?\",\n    answer=\"\",\n)\nresponse = gemma_lm.generate(prompt, max_length=128)\ndisplay(Markdown(colorize_text(response)))","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:36:56.462560Z","iopub.execute_input":"2024-11-10T10:36:56.463256Z","iopub.status.idle":"2024-11-10T10:37:06.846125Z","shell.execute_reply.started":"2024-11-10T10:36:56.463229Z","shell.execute_reply":"2024-11-10T10:37:06.845300Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWhat are the complications of Paget's Disease of Bone ?\n\n\n\n**<font color='green'>Answer:</font>**\nComplications of Paget's Disease of Bone Paget's disease can cause a number of complications, including: - bone fractures, which can be painful and lead to disability  - bone pain  - bone deformities, such as bowed legs or a humped back  - bone loss, which can lead to a loss of height  - bone lesions, which can cause pain and swelling  - joint pain and swelling  - loss of teeth"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"prompt = template.format(\n    question=\"What are the treatments for Diabetes ?\",\n    answer=\"\",\n)\nresponse = gemma_lm.generate(prompt, max_length=128)\ndisplay(Markdown(colorize_text(response)))","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:37:10.089693Z","iopub.execute_input":"2024-11-10T10:37:10.090150Z","iopub.status.idle":"2024-11-10T10:37:13.126749Z","shell.execute_reply.started":"2024-11-10T10:37:10.090115Z","shell.execute_reply":"2024-11-10T10:37:13.125759Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWhat are the treatments for Diabetes ?\n\n\n\n**<font color='green'>Answer:</font>**\nThere is no cure for diabetes, but there are many ways to manage it. The goal of treatment is to keep blood glucose levels as close to normal as possible. This can be done with diet, exercise, and medicines. The type of treatment you need depends on your blood glucose levels and how well you can follow a treatment plan. If you have type 2 diabetes, you may need to take medicines to help control your blood glucose levels. If you have type 1 diabetes, you will need to take insulin to control your blood glucose levels."},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"# Save the model","metadata":{}},{"cell_type":"code","source":"preset = \"./medical_gemma\"\n# Save the model to the preset directory.\ngemma_lm.save_to_preset(preset)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T10:37:18.679748Z","iopub.execute_input":"2024-11-10T10:37:18.680382Z","iopub.status.idle":"2024-11-10T10:38:06.797128Z","shell.execute_reply.started":"2024-11-10T10:37:18.680351Z","shell.execute_reply":"2024-11-10T10:38:06.795891Z"},"trusted":true},"outputs":[],"execution_count":18}]}